{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from pydotplus import graph_from_dot_data\n",
    "from IPython.display import Image\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score,f1_score,fbeta_score,mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score,f1_score,fbeta_score,classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "df=pd.read_csv(r'E:\\Project\\1-Output\\4 DATASETS WITH BEST 25 FEATURES\\Best_25_Features_Dataset-3.csv')\n",
    "X = df.loc[:,df.columns!=\"Label\"]\n",
    "y = df[\"Label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s =time.time()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "params_grid = {\n",
    "               'max_depth': [5,8,10,15,20,25,30,50],\n",
    "               'max_features': ['log2','sqrt',0.25,0.5,0.6,1.0],\n",
    "               'min_samples_leaf': [1,25,50,70],\n",
    "               'min_samples_split': [2,5,10,20]\n",
    "              }\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=42)\n",
    "grid_search = GridSearchCV(RandomForestClassifier (random_state = 42), param_grid = params_grid, n_jobs = -1, cv = cv, scoring = 'accuracy')\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters: %s\" % (grid_result.best_params_))\n",
    "\n",
    "gbc_clf2 = RandomForestClassifier(max_depth = grid_result.best_params_.get('max_depth'),\n",
    "                     max_features = grid_result.best_params_.get('max_features'),\n",
    "                     min_samples_leaf = grid_result.best_params_.get('min_samples_leaf'),\n",
    "                     min_samples_split = grid_result.best_params_.get('min_samples_split'),\n",
    "                     random_state=42)\n",
    "\n",
    "gbc_clf2.fit(X_train, y_train)\n",
    "\n",
    "e=time.time()\n",
    "exe_time = round(e - s)\n",
    "print(\"Execution Time in Seconds :\", exe_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters: {'max_depth': 8, 'max_features': 0.25, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
    "Execution Time in Seconds : 322\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERFORMANCE EVALUATION OF RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = gbc_clf2.predict(X_train)\n",
    "y_test_pred = gbc_clf2.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "\n",
    "print(\"-------------------------------------Metrics------------------------------------------\")\n",
    "print(\"Test accuracy score {:.4f}\".format(accuracy_score(y_test, y_test_pred) * 100))\n",
    "print(\"Test Recall {:.4f}\".format(recall_score(y_test, y_test_pred) * 100))\n",
    "print(\"Test Precision {:.4f}\".format(precision_score(y_test, y_test_pred) * 100))\n",
    "print(\"Test F1 Score {:.4f}\".format(f1_score(y_test, y_test_pred) * 100))\n",
    "print(\"Test F2 Score {:.4f}\".format(fbeta_score(y_test, y_test_pred, beta=2.0) * 100))\n",
    "\n",
    "print(\"--------------------------TPR, TNR, FPR, FNR------------------------------------------\")\n",
    "TPR = tp / (tp + fn)\n",
    "TNR = tn / (tn + fp)\n",
    "FPR = fp / (fp + tn)\n",
    "FNR = fn / (fn + tp)\n",
    "print(\"TPR {:.4f}\".format(TPR))\n",
    "print(\"TNR {:.4f}\".format(TNR))\n",
    "print(\"FPR {:.4f}\".format(FPR))\n",
    "print(\"FNR {:.4f}\".format(FNR))\n",
    "print(confusion_matrix(y_test,y_test_pred))\n",
    "report = classification_report(y_test, y_test_pred)\n",
    "print(report)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s =time.time()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "parameters = {\n",
    "              'n_estimators': [10,50,100],\n",
    "              'learning_rate': [0.01,0.05,0.1,0.5],\n",
    "              'algorithm': ['SAMME','SAMME.R'],\n",
    "              'estimator__max_depth': [1,50,100,200,300,400,500],\n",
    "              'estimator__max_features': [2,10,100,200,300,400,500] \n",
    "             }\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=42)\n",
    "RD_search = GridSearchCV(AdaBoostClassifier(estimator=DecisionTreeClassifier(), random_state=42),parameters,cv=cv,n_jobs=-1,scoring='accuracy')\n",
    "RD_result = RD_search.fit(X_train, y_train)\n",
    "print(\"Best parameters: %s\" % (RD_result.best_params_))\n",
    "\n",
    "gbc_clf2 = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=RD_result.best_params_['estimator__max_depth'], \n",
    "                              max_features=RD_result.best_params_['estimator__max_features']),\n",
    "                              learning_rate=RD_result.best_params_['learning_rate'],\n",
    "                              n_estimators=RD_result.best_params_['n_estimators'],\n",
    "                              algorithm=RD_result.best_params_['algorithm'],\n",
    "                              random_state=42)\n",
    "\n",
    "gbc_clf2.fit(X_train, y_train)\n",
    "\n",
    "e=time.time()\n",
    "exe_time = round(e - s)\n",
    "print(\"Execution Time in Seconds :\", exe_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters: {'algorithm': 'SAMME.R', 'estimator__max_depth': 1, 'estimator__max_features': 100, 'learning_rate': 0.2, 'n_estimators': 460}\n",
    "Execution Time in Seconds : 2249\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERFORMANCE EVALUATION OF ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = gbc_clf2.predict(X_train)\n",
    "y_test_pred = gbc_clf2.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "\n",
    "print(\"-------------------------------------Metrics------------------------------------------\")\n",
    "print(\"Test accuracy score {:.4f}\".format(accuracy_score(y_test, y_test_pred) * 100))\n",
    "print(\"Test Recall {:.4f}\".format(recall_score(y_test, y_test_pred) * 100))\n",
    "print(\"Test Precision {:.4f}\".format(precision_score(y_test, y_test_pred) * 100))\n",
    "print(\"Test F1 Score {:.4f}\".format(f1_score(y_test, y_test_pred) * 100))\n",
    "print(\"Test F2 Score {:.4f}\".format(fbeta_score(y_test, y_test_pred, beta=2.0) * 100))\n",
    "\n",
    "print(\"--------------------------TPR, TNR, FPR, FNR------------------------------------------\")\n",
    "TPR = tp / (tp + fn)\n",
    "TNR = tn / (tn + fp)\n",
    "FPR = fp / (fp + tn)\n",
    "FNR = fn / (fn + tp)\n",
    "print(\"TPR {:.4f}\".format(TPR))\n",
    "print(\"TNR {:.4f}\".format(TNR))\n",
    "print(\"FPR {:.4f}\".format(FPR))\n",
    "print(\"FNR {:.4f}\".format(FNR))\n",
    "print(confusion_matrix(y_test,y_test_pred))\n",
    "report = classification_report(y_test, y_test_pred)\n",
    "print(report)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRADIENTBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s =time.time()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "parameters = {\n",
    "              'loss': ['exponential'],\n",
    "              'learning_rate': [0.01,0.05,0.1,0.5],\n",
    "              'min_samples_split': [2,5,7,9],\n",
    "              'min_samples_leaf': [3,5,6,8],\n",
    "              'max_depth': [3,5,10,15],\n",
    "              'max_features': [3,5,10,15],\n",
    "              'criterion': ['friedman_mse'],\n",
    "              'subsample': [0.5,0.8,0.9,1.0],\n",
    "              'n_estimators': [10,50,100]\n",
    "             }\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=42)\n",
    "RD_search = GridSearchCV(GradientBoostingClassifier(random_state=42), parameters, cv=cv, n_jobs=-1, scoring='accuracy')\n",
    "RD_result = RD_search.fit(X_train, y_train)\n",
    "print(\"Best parameters: %s\" % (RD_result.best_params_))\n",
    "\n",
    "gbc_clf2 = GradientBoostingClassifier(learning_rate=RD_result.best_params_.get('learning_rate'),\n",
    "                                      loss=RD_result.best_params_.get('loss'),\n",
    "                                      min_samples_split=RD_result.best_params_.get('min_samples_split'),\n",
    "                                      min_samples_leaf=RD_result.best_params_.get('min_samples_leaf'),\n",
    "                                      max_depth=RD_result.best_params_.get('max_depth'),\n",
    "                                      max_features=RD_result.best_params_.get('max_features'),\n",
    "                                      criterion=RD_result.best_params_.get('criterion'),\n",
    "                                      subsample=RD_result.best_params_.get('subsample'),\n",
    "                                      n_estimators=RD_result.best_params_.get('n_estimators'),\n",
    "                                      random_state=42)\n",
    "\n",
    "gbc_clf2.fit(X_train, y_train)\n",
    "\n",
    "e=time.time()\n",
    "exe_time = round(e - s)\n",
    "print(\"Execution Time in Seconds :\", exe_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters: {'criterion': 'friedman_mse', 'learning_rate': 0.05, 'loss': 'exponential', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 50, 'subsample': 0.7}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERFORMANCE EVALUATION OF GRADIENTBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = gbc_clf2.predict(X_train)\n",
    "y_test_pred = gbc_clf2.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "\n",
    "print(\"-------------------------------------Metrics------------------------------------------\")\n",
    "print(\"Test accuracy score {:.4f}\".format(accuracy_score(y_test, y_test_pred) * 100))\n",
    "print(\"Test Recall {:.4f}\".format(recall_score(y_test, y_test_pred) * 100))\n",
    "print(\"Test Precision {:.4f}\".format(precision_score(y_test, y_test_pred) * 100))\n",
    "print(\"Test F1 Score {:.4f}\".format(f1_score(y_test, y_test_pred) * 100))\n",
    "print(\"Test F2 Score {:.4f}\".format(fbeta_score(y_test, y_test_pred, beta=2.0) * 100))\n",
    "\n",
    "print(\"--------------------------TPR, TNR, FPR, FNR------------------------------------------\")\n",
    "TPR = tp / (tp + fn)\n",
    "TNR = tn / (tn + fp)\n",
    "FPR = fp / (fp + tn)\n",
    "FNR = fn / (fn + tp)\n",
    "print(\"TPR {:.4f}\".format(TPR))\n",
    "print(\"TNR {:.4f}\".format(TNR))\n",
    "print(\"FPR {:.4f}\".format(FPR))\n",
    "print(\"FNR {:.4f}\".format(FNR))\n",
    "print(confusion_matrix(y_test,y_test_pred))\n",
    "report = classification_report(y_test, y_test_pred)\n",
    "print(report)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s =time.time()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "parameters = {\n",
    "              'objective': ['binary:logistic'],\n",
    "              'learning_rate': [0.05,0.1,0.5,1.0], \n",
    "              'max_depth': [2,4,6,8],\n",
    "              'min_child_weight': [3,5,7,9],\n",
    "              'subsample':  [0.1,0.3,0.5,0.7],\n",
    "              'colsample_bytree': [0.3,0.5,0.8],\n",
    "              'n_estimators': [10,50,100],\n",
    "              'gamma': [0.1,0.3,0.4,0.7]\n",
    "              }\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=42)\n",
    "RD = GridSearchCV(xgb.XGBClassifier(random_state=42), parameters, n_jobs=1, cv=cv, scoring='accuracy',verbose=0, refit=True)\n",
    "RD_result = RD.fit(X_train, y_train)\n",
    "print(\"Best parameters: %s\" % (RD.best_params_))\n",
    "\n",
    "gbc_clf2 = xgb.XGBClassifier(objective = RD.best_params_.get('objective'),\n",
    "                     learning_rate = RD.best_params_.get('learning_rate'),\n",
    "                     max_depth = RD.best_params_.get('max_depth'),\n",
    "                     min_child_weight = RD.best_params_.get('min_child_weight'),\n",
    "                     subsample = RD.best_params_.get('subsample'),\n",
    "                     colsample_bytree = RD.best_params_.get('colsample_bytree'),\n",
    "                     n_estimators = RD.best_params_.get('n_estimators'),\n",
    "                     gamma = RD.best_params_.get('gamma'),\n",
    "                     random_state=42)\n",
    "\n",
    "gbc_clf2.fit(X_train, y_train)\n",
    "\n",
    "e=time.time()\n",
    "exe_time = round(e - s)\n",
    "print(\"Execution Time in Seconds :\", exe_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters: {'colsample_bytree': 0.2, 'gamma': 0.8, 'learning_rate': 0.6, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 50, 'objective': 'binary:logistic', 'subsample': 0.7}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERFORMANCE EVALUATION OF XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = gbc_clf2.predict(X_train)\n",
    "y_test_pred = gbc_clf2.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "\n",
    "print(\"-------------------------------------Metrics------------------------------------------\")\n",
    "print(\"Test accuracy score {:.4f}\".format(accuracy_score(y_test, y_test_pred) * 100))\n",
    "print(\"Test Recall {:.4f}\".format(recall_score(y_test, y_test_pred) * 100))\n",
    "print(\"Test Precision {:.4f}\".format(precision_score(y_test, y_test_pred) * 100))\n",
    "print(\"Test F1 Score {:.4f}\".format(f1_score(y_test, y_test_pred) * 100))\n",
    "print(\"Test F2 Score {:.4f}\".format(fbeta_score(y_test, y_test_pred, beta=2.0) * 100))\n",
    "\n",
    "print(\"--------------------------TPR, TNR, FPR, FNR------------------------------------------\")\n",
    "TPR = tp / (tp + fn)\n",
    "TNR = tn / (tn + fp)\n",
    "FPR = fp / (fp + tn)\n",
    "FNR = fn / (fn + tp)\n",
    "print(\"TPR {:.4f}\".format(TPR))\n",
    "print(\"TNR {:.4f}\".format(TNR))\n",
    "print(\"FPR {:.4f}\".format(FPR))\n",
    "print(\"FNR {:.4f}\".format(FNR))\n",
    "print(confusion_matrix(y_test,y_test_pred))\n",
    "report = classification_report(y_test, y_test_pred)\n",
    "print(report)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
